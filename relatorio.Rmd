---
title: "Relatorio"
author: "Fabio Firanzi, Heitor Dias, Julia Fideles, Matheus Soares, Tiago Braga"
date: "2025-11-11"
output:
  pdf_document:
    latex_engine: pdlatex
    keep_tex: true
header-includes: 
 \usepackage[T1]{fontenc} 
 \usepackage[utf8]{inputenc} 
 \usepackage[portuguese]{babel}
 \usepackage{booktabs} 
 \usepackage{float} 
 \usepackage{graphicx}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
#Carregar as bibliotecas necessárias
library(readxl)
library(dplyr)
library(ggplot2)
library(kableExtra)
library(knitr)
```

# Analise da area de conhecimento de Humanas: Heitor

```{r setup-e-carga, message=FALSE, warning=FALSE}
#Carregar o banco de dados

amostra_10p <- read.csv("amostra_10p.csv")

```

# 1.1 Analise da variavel de presença na prova de humanas
Foi feita uma analise da area de conhecimento de Ciências Humanas do Enem, utilizando a varivel: TP_PRESENCA_CH

## 1.1 Tabela e Gráfico de Frequências
Busca indentificar se o aluno estava presente, ausente ou se foi eliminado da prova de ciências humanas, e, com isso, expressar a porcentagem e os valores absolutos da variável TP_PRESENCA_CH.

```{r analise_variavel_presenca, message=FALSE, warning=FALSE}
# Item 1: Tabela de Frequências (Absoluta e Relativa)

# Vamos renomear os valores 0 e 1 para ficarem mais claros
tabela_presenca <- amostra_10p %>%
  mutate(Presenca = case_when(
    TP_PRESENCA_CH == 0 ~ "Ausente",
    TP_PRESENCA_CH == 1 ~ "Presente",
    TRUE ~ "Eliminado da prova"
  )) %>%
  count(Presenca, sort = TRUE) %>% # Conta as ocorrências
  mutate(Percentual = prop.table(n) * 100) # Calcula o percentual

# Mostra a tabela formatada (ótimo para o relatório)
kable(tabela_presenca,
      caption = "Tabela 1: Frequência de Presença na Prova de CH",
      col.names = c("Status", "Frequência (N)", "Percentual (%)"),
      digits = 2) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
      full_width = FALSE, 
      position = "center") %>%
      row_spec(0, bold = TRUE, background = "#D3D3D3")

# Item 2: Gráfico (Gráfico de Barras)
ggplot(tabela_presenca, aes(x = reorder(Presenca, -n), y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = n), vjust = -0.5) + # Adiciona o número no topo
  
  scale_y_continuous(
    # 3. ALTERAÇÃO AQUI: Formatamos o EIXO Y (lateral)
    labels = scales::label_number(big.mark = ".", decimal.mark = ","),
    
    # 4. ALTERAÇÃO AQUI: Aumentamos o teto do gráfico em 10% para o número não cortar
    expand = expansion(mult = c(0, 0.1)) 
  ) +
  
  labs(title = "Gráfico 1: Presença na Prova de CH",
       x = "Status de Presença",
       y = "Número de Alunos") +
  theme_minimal()

```

No "Gráfico 1: Presença na Prova de CH"
Com base na analise do gráfico "Presença na Prova Ciências Humanas" e da tabela "Frequência da Presença na Prova de Ciências Humanas" foi possível determinar que no Exame Nacional do Ensino Médio (ENEM), edição de 2024, o número de alunos presentes foi de aproximadamente 2,73 vezes maior que o número de alunos ausentes. Isso se revela, atraves da variavel




# 1.3 Analise da variavel de presença na prova de humanas

```{r analise-medidas-estatistica}
# 1. Carregar o arquivo de dados
# (Assumindo que você já o carregou como 'amostra_10p')
dados <- read.csv("amostra_10p.csv") 

# 2. Criar a Tabela Resumo por Região
tabela_resumo_regiao <- amostra_10p %>%
  
  # PASSO 1: FILTRAR
  # Filtra apenas quem estava PRESENTE e tinha nota de CH
  filter(TP_PRESENCA_CH == 1, !is.na(NU_NOTA_CH), NU_NOTA_CH > 0) %>%
  
  # PASSO 2: "ETIQUETAR" (MUTATE)
  # Cria a nova coluna "Regiao" com base no seu critério
  mutate(Regiao = case_when(
    SG_UF_PROVA %in% c('AM', 'AC', 'RO', 'RR', 'AP', 'PA', 'TO') ~ "Norte",
    SG_UF_PROVA %in% c('MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', 'SE', 'BA') ~ "Nordeste",
    SG_UF_PROVA %in% c('SP', 'MG', 'RJ', 'ES') ~ "Sudeste",
    SG_UF_PROVA %in% c('GO', 'DF', 'MT', 'MS') ~ "Centro-Oeste",
    SG_UF_PROVA %in% c('PR', 'SC', 'RS') ~ "Sul"
  )) %>%
  
  # PASSO 3: AGRUPAR
  # Agora agrupamos pela nova coluna
  group_by(Regiao) %>%
  
  # PASSO 4: CALCULAR AS ESTATÍSTICAS
  # Resumimos os dados para cada Regiao
  summarise(
    Media = mean(NU_NOTA_CH),
    Mediana = median(NU_NOTA_CH),
    Variancia = var(NU_NOTA_CH),
    Desvio_Padrao = sd(NU_NOTA_CH),
    Minimo = min(NU_NOTA_CH),
    Maximo = max(NU_NOTA_CH),
    N_Alunos = n()
  ) %>%
  
  # PASSO 5: ORDENAR (Opcional)
  arrange(desc(Media))

# 3. Exibir a tabela formatada
tabela_resumo_regiao %>%
  kable(
    caption = "Tabela Resumo: Estatísticas das Notas de CH por Região",
    col.names = c("Região", "Média", "Mediana", "Variância", "Desv. Padrão", "Mínimo", "Máximo", "Nº de Alunos"),
    digits = 2, # Arredonda os números
    format = "html"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )

```

```{r}
# Calcular a média de nota de CH por estado
medias_por_estado <- amostra_10p %>%
  filter(TP_PRESENCA_CH == 1 & !is.na(NU_NOTA_CH)) %>% # Filtra presentes e com nota válida
  group_by(SG_UF_PROVA) %>%
  summarise(
    Media_Nota_CH = mean(NU_NOTA_CH),
    Numero_de_Alunos = n() # É importante saber o N de cada estado
  ) %>%
  arrange(desc(Media_Nota_CH)) # Ordena da maior média para a menor

# Exibir os 10 estados com maiores médias
medias_por_estado %>%
  head(10) %>% # Pega apenas os 10 primeiros
  kable(
    caption = "Tabela 4: Top 10 Estados por Média em Ciências Humanas",
    col.names = c("Estado", "Média da Nota", "Nº de Alunos"),
    digits = 2,
    format = "html"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, 
                position = "center") %>%
  row_spec(0, bold = TRUE, background = "#D3D3D3") # Estilo do cabeçalho

# Calcular o desvio padrão e o coeficiente de variancia
analise_dispersao_estado <- amostra_10p %>%
  filter(TP_PRESENCA_CH == 1 & !is.na(NU_NOTA_CH)) %>%
  group_by(SG_UF_PROVA) %>%
  summarise(
    Media = mean(NU_NOTA_CH),
    Desvio_Padrao = sd(NU_NOTA_CH),
    Coef_Variacao_Percent = (Desvio_Padrao / Media) * 100,
    Numero_de_Alunos = n()
  ) %>%
  
  arrange(Coef_Variacao_Percent) 

# Exibir a tabela
analise_dispersao_estado %>%
  kable(
    caption = "Tabela 5: Análise de Dispersão das Notas de CH por Estado",
    col.names = c("Estado", "Média", "Desvio Padrão", "CV (%)", "Nº de Alunos"),
    digits = 2,
    format = "html"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE, 
                position = "center") %>%
  row_spec(0, bold = TRUE, background = "#D3D3D3")

# Primeiro, criamos o conjunto de dados filtrado (apenas presentes com nota)
dados_ch_presentes <- amostra_10p %>%
  filter(TP_PRESENCA_CH == 1 & !is.na(NU_NOTA_CH))

# Agora, o Boxplot
ggplot(dados_ch_presentes, aes(x = reorder(SG_UF_PROVA, NU_NOTA_CH, FUN = median), y = NU_NOTA_CH)) +
  geom_boxplot(fill = "lightblue", outlier.shape = 21, outlier.size = 2) +
  coord_flip() + # Essencial para ler os 27 estados
  labs(
    title = "Gráfico 6: Boxplot das Notas de CH por Estado",
    subtitle = "Ordenado pela Mediana (Quartil 2)",
    x = "Estado (UF)",
    y = "Nota em Ciências Humanas"
  ) +
  theme_minimal()

```


```{r}
VARIAVEL_EM_ANALISE <- "NU_NOTA_CH"

dados_analise <- amostra_10p %>%
  # Filtra alunos PRESENTES na prova de CH
  filter(TP_PRESENCA_CH == 1) %>%
  # Seleciona apenas a nota de CH e renomeia para "Valor"
  select(Valor = all_of(VARIAVEL_EM_ANALISE)) %>%
  # Remove NAs (notas nulas)
  filter(!is.na(Valor))

```



# 1.3.1 Tabela de Frequências (por Classes)

Para dados quantitativos contínuos, criamos classes (faixas de valores) para a tabela de frequências.

```{r}
# 1. Definir os limites das classes (ex: de 50 em 50 pontos)
limites_classes <- seq(
  from = floor(min(dados_analise$Valor) / 50) * 50, # Arredonda para baixo
  to = ceiling(max(dados_analise$Valor) / 50) * 50, # Arredonda para cima
  by = 50 # Intervalo da classe
)

# 2. Criar a tabela de frequências
tabela_freq <- dados_analise %>%
  mutate(Classe = cut(
    Valor,
    breaks = limites_classes,
    right = FALSE # Intervalo [fechado, aberto)
  )) %>%
  count(Classe, name = "Frequencia") %>%
  filter(!is.na(Classe)) %>% # Remove NAs que podem surgir do 'cut'
  mutate(
    Percentual = (Frequencia / sum(Frequencia)) * 100,
    Acumulada = cumsum(Frequencia),
    Percentual_Acumulado = cumsum(Percentual)
  )

# 3. Exibir a tabela formatada
tabela_freq %>%
  kable(
    caption = "Tabela 1: Tabela de Frequências por Classe (Nota de CH)",
    col.names = c("Classe", "Freq. (N)", "%", "Freq. Acum.", "% Acum."),
    digits = 2,
    format = "html"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE) %>%
  # Destaca a Classe Modal (maior frequência)
  row_spec(which.max(tabela_freq$Frequencia), 
           bold = TRUE, 
           background = "#DFF0D8")


```

Interpretação da Tabela 1: A faixa de nota com maior frequência (a Classe Modal) é [500, 550), contendo 21.05% dos alunos.

# 1.3.2 Medidas Descritivas

Calculamos as principais medidas de tendência central, dispersão e posição.

```{r}


# 1. Calcular Medidas usando summary()
sumario <- summary(dados_analise$Valor)

# 2. Calcular Medidas Adicionais
medidas_adicionais <- tibble(
  Medida = c(
    "Variância",
    "Desvio Padrão",
    "Amplitude Total (Range)",
    "Coef. de Variação (CV)"
  ),
  Valor = c(
    var(dados_analise$Valor),
    sd(dados_analise$Valor),
    max(dados_analise$Valor) - min(dados_analise$Valor),
    (sd(dados_analise$Valor) / mean(dados_analise$Valor)) * 100
  )
)

# 3. Juntar tudo numa tabela
# O summary() já nos dá: Mínimo, Q1, Mediana, Média, Q3, Máximo
tabela_medidas <- tibble(
  Medida = names(sumario),
  Valor = as.numeric(sumario)
) %>%
  # Adiciona as medidas extras
  bind_rows(medidas_adicionais)

# 4. Exibir a tabela de medidas
tabela_medidas %>%
  kable(
    caption = "Tabela 2: Medidas Descritivas para Nota de CH",
    col.names = c("Medida", "Valor"),
    digits = 2,
    format = "html"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), 
                full_width = FALSE)


```

Sobre a Moda: Para dados contínuos, não se calcula uma "Moda" (valor único), pois é raro um valor se repetir. Analisamos a Classe Modal, como visto na Tabela 1 (a faixa de valores mais frequente).




# 1.4 Correlação e Regressão Linear Simples

```{r}
# 2. Filtrar os dados para a regressão
# É MUITO IMPORTANTE filtrar os dados corretamente:
# - Aluno deve estar PRESENTE em AMBAS as provas (CH e LC)
# - Aluno deve ter nota válida (não-NA) em AMBAS
# - Aluno deve ter nota > 0 em AMBAS (para remover notas zeradas)

dados_regressao <- amostra_10p %>%
  filter(
    TP_PRESENCA_CH == 1,
    TP_PRESENCA_LC == 1,
    !is.na(NU_NOTA_CH),
    !is.na(NU_NOTA_LC),
    NU_NOTA_CH > 0,
    NU_NOTA_LC > 0
  ) %>%
  # Seleciona apenas as colunas que vamos usar
  select(NU_NOTA_CH, NU_NOTA_LC)

# Mostra o número de observações válidas para esta análise
paste("Total de observações válidas para a regressão:", nrow(dados_regressao))

# Calcula a correlação
cor_coef <- cor(dados_regressao$NU_NOTA_LC, dados_regressao$NU_NOTA_CH)

# Exibe o resultado
cat(paste0("O Coeficiente de Correlação (r) entre LC e CH é: ", round(cor_coef, 4)))

ggplot(dados_regressao, aes(x = NU_NOTA_LC, y = NU_NOTA_CH)) +
  # 1. Nuvem de pontos
  geom_point(alpha = 0.2, color = "blue") + # 'alpha' ajuda a ver a densidade
  
  # 2. Reta de Regressão (calculada automaticamente pelo ggplot)
  geom_smooth(method = "lm", color = "red", linewidth = 1.5, se = TRUE) +
  
  # Títulos e formatação
  labs(
    title = "Gráfico de Regressão: Nota de Humanas vs. Nota de Linguagens",
    x = "Nota de Linguagens e Códigos (LC)",
    y = "Nota de Ciências Humanas (CH)"
  ) +
  theme_minimal()


```

